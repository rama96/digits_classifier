{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# MNIST using simple ANN baseline model","metadata":{}},{"cell_type":"markdown","source":"In this notebook , we are going to go through the details on how to build a simple deep learning model (ANN) to predict the labels of handwritten digits given it's image . We would be using MNIST dataset from Kaggle for training the model ([link](https://www.kaggle.com/competitions/digit-recognizer)) .I'll try my best to keep things as simple as possible here and explain the steps and the process we follow as we go through this notebook . \nThe first step is to inspect the dataset, the format in which the images are stored and the correspoinding labels assciated with the same .  ","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-07-03T13:00:11.549167Z","iopub.execute_input":"2022-07-03T13:00:11.549706Z","iopub.status.idle":"2022-07-03T13:00:11.560694Z","shell.execute_reply.started":"2022-07-03T13:00:11.549668Z","shell.execute_reply":"2022-07-03T13:00:11.559360Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"We notice that the data is stored in the form of csv . We can quickly use pandas to read the CSVs in the form of dataframe and go though it's contents . We read through both the train and test files to see the columns in each of them and that'll give us an idea on what the target variable is . ","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv(\"/kaggle/input/digit-recognizer/train.csv\")\ntest_df = pd.read_csv(\"/kaggle/input/digit-recognizer/test.csv\")\nprint(train_df.shape , test_df.shape)\nprint(\"Train Cols : \" , train_df.columns)\nprint(\"Test Cols : \" , test_df.columns)\nprint(\" Label -  \" , [i for i in train_df.columns if i not in test_df.columns] )","metadata":{"execution":{"iopub.status.busy":"2022-07-03T13:00:18.012690Z","iopub.execute_input":"2022-07-03T13:00:18.013131Z","iopub.status.idle":"2022-07-03T13:00:22.605178Z","shell.execute_reply.started":"2022-07-03T13:00:18.013093Z","shell.execute_reply":"2022-07-03T13:00:22.603953Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"There are 42K Rows in the training dataset and 28K in the test_dataset . From the column names , we conculde that the pictures are stored in the form of rows where the column - <b> pixel_1 </b> indicates the pixel density value in the <b> cell_no[1] </b> in the image  . Since there are values till pixel_783 , there are 784 pixel counts which means it's a 28*28 image . To find the target column , we simply check for columns in the training dataset that is not a part of test dataset","metadata":{}},{"cell_type":"markdown","source":"## Creating the dataset class for the pytorch model","metadata":{}},{"cell_type":"markdown","source":"We are going to follow best practices of pytorch get the data in the form of <b>Dataset</b> since it makes life easier for us to create the dataloaders which would later be used in the training processes . Here we create our own custom class inheriting the <b> Dataset </b> class specifying how to access the elements of the dataset undet the __getitem__ method . Under this method , we read the data and store it under __img_df__ and extract the image , convert them into 28*28 numpy array  , bring the values under the range [0,1] and perform transforms on both the image and the label seperately and returns them in the form of X , y tensors . This custom class accepts the following arguments\n* csv_name - The name under which the data is stored \n* img_dir - the path of the directory under which the file is stored.\n* transform - The tranforms that needs to be done on the image vector \n* target_transform - The transforms that needs to be done on the target variable","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset\nfrom torchvision import datasets\nfrom torchvision.transforms import ToTensor , Lambda\n\nclass CustomMNISTDataset(Dataset):\n    def __init__(self, csv_name, img_dir, transform=None, target_transform=None , label_name = \"label\"):\n        \n        self.img_filename = csv_name\n        self.img_dir = img_dir\n        self.transform = transform\n        self.target_transform = target_transform\n        self.label_name = label_name\n        \n        img_path = os.path.join(self.img_dir, self.img_filename)\n        self.img_df = pd.read_csv(img_path)\n\n    def __len__(self):\n        return len(self.img_df)\n\n    def __getitem__(self, idx):\n        \n        # Extracting all the other columns except label_name\n        img_cols = [ i for i in self.img_df.columns if i not in self.label_name]\n        \n        image = self.img_df.iloc[[idx]][img_cols].values\n        label = int(self.img_df.iloc[[idx]][self.label_name].values)\n        \n        # Reshaping the array from 1*784 to 28*28\n        \n        image = image.reshape(28,28)\n        # image = image.astype(float)\n        \n        # Scaling the image so that the values only range between 0 and 1\n        image = image/255.0\n        \n        if self.transform:\n            image = self.transform(image)\n        if self.target_transform:\n            label = self.target_transform(label)\n        \n        image = image.to(torch.float)\n        # label = label.to(torch.float)\n        \n        return image, label","metadata":{"execution":{"iopub.status.busy":"2022-07-03T13:29:16.981643Z","iopub.execute_input":"2022-07-03T13:29:16.982456Z","iopub.status.idle":"2022-07-03T13:29:16.997683Z","shell.execute_reply.started":"2022-07-03T13:29:16.982413Z","shell.execute_reply":"2022-07-03T13:29:16.996287Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"### Distribution of target labels","metadata":{}},{"cell_type":"markdown","source":"Before actually creating the datasets , we just peek into the training dataset just to see how many target variables are actually present in the dataset . This will give us a sense of whether the dataset is skewed towards a particular label compared to others","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv(\"/kaggle/input/digit-recognizer/train.csv\")\ntrain_df['label'].value_counts().sort_index()","metadata":{"execution":{"iopub.status.busy":"2022-07-03T13:17:17.095958Z","iopub.execute_input":"2022-07-03T13:17:17.096467Z","iopub.status.idle":"2022-07-03T13:17:19.935129Z","shell.execute_reply.started":"2022-07-03T13:17:17.096425Z","shell.execute_reply":"2022-07-03T13:17:19.933866Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"We see that the distribution of the labels are fairly equal and is not highly skewed towards any particular varibale here.","metadata":{}},{"cell_type":"markdown","source":"### Distribution of labels in both train and valid sets","metadata":{}},{"cell_type":"markdown","source":"To measure at the actual model performance , it is required to create train and valid subsets from our training_data set . We will only use the train_subset for training the model and will check the performance of the same with the valid dataset . For creating the valid dataset , we will stratify using the y-labels just to ensure that the distribution of both the train and valid subsets remain the same","metadata":{}},{"cell_type":"code","source":"## Illustration of creating a validation set \n\nfrom sklearn.model_selection import train_test_split\nindices = list(range(len(train_df)))\n\ntrain_indices , test_indices = train_test_split(indices, test_size=0.1, stratify=train_df['label'])\n# train_indices , test_indices = train_test_split(indices, test_size=0.1)\n\nlen(train_indices) , len(test_indices) , len(train_df)\n\ntrain_subset = train_df.loc[train_indices]\nval_subset = train_df.loc[test_indices]\n\nprint(\"Distribution of target values in training dataset ; \")\nprint( train_subset['label'].value_counts().sort_index() / train_subset['label'].value_counts().sort_index().sum() )\n\nprint(\"Distribution of target values in validation dataset ; \")\nprint( val_subset['label'].value_counts().sort_index() / val_subset['label'].value_counts().sort_index().sum() )","metadata":{"execution":{"iopub.status.busy":"2022-07-03T13:31:05.698180Z","iopub.execute_input":"2022-07-03T13:31:05.698793Z","iopub.status.idle":"2022-07-03T13:31:06.073873Z","shell.execute_reply.started":"2022-07-03T13:31:05.698740Z","shell.execute_reply":"2022-07-03T13:31:06.072486Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"## Creating Train Dataset using train data","metadata":{}},{"cell_type":"markdown","source":"We will go ahead and create the train_dataset using the class we have defined above . As for the arguments , we supply the directory and the csv_name based on the values provided below . For transforms , we use the function ToTensor() which converts the numpy aray to tensor and Normalize(mean , std) helping us normalize the dataset with the given mean and standard deviation so that the values are not out pf proportion . We keep the target_transform value as None since nothing needs to be done on the target variable","metadata":{}},{"cell_type":"code","source":"from torchvision import transforms\n\n# Crerating a temp dataset\ntrain_csv_name = \"train.csv\"\ntest_csv_name = \"test.csv\"\nimg_dir = \"/kaggle/input/digit-recognizer/\"\n\n# Converting X variables to Tensors\ntransforms = transforms.Compose( [transforms.ToTensor() , transforms.Normalize((0.5,), (0.5,)) , ] )\n\n# Converting y-labels to one hot encoding\n# target_transform = Lambda(lambda y: torch.zeros(\n#     len(train_df['label'].unique()), dtype=torch.float).scatter_(dim=0, index=torch.tensor(y), value=1))\n# This is not need since we are going to be using cross entropy loss function\n\nlabel_name = \"label\"\n\ntrain_dataset = CustomMNISTDataset(csv_name = train_csv_name , img_dir = img_dir , transform = transforms , target_transform = None , label_name = label_name)\n\n# Inspecting the fist line item under dataset\nx0 , y0 = train_dataset[0]\nprint(x0.shape , y0)","metadata":{"execution":{"iopub.status.busy":"2022-07-03T13:31:13.967573Z","iopub.execute_input":"2022-07-03T13:31:13.968003Z","iopub.status.idle":"2022-07-03T13:31:16.838895Z","shell.execute_reply.started":"2022-07-03T13:31:13.967969Z","shell.execute_reply":"2022-07-03T13:31:16.837271Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"### Plotting the datapoints of train_dataset","metadata":{}},{"cell_type":"code","source":"# Ploting some of the datapoints in the dataset\nimport matplotlib.pyplot as plt\n\n# sample_img , sample_lbl = temp_train_dataset[3]\nfigure = plt.figure(figsize=(8, 8))\ncols, rows = 3, 3\nfigure.add_subplot(rows, cols, 1)\nfor i in range(1, cols * rows + 1):\n    sample_idx = torch.randint(len(train_dataset), size=(1,)).item()\n    sample_img , sample_lbl = train_dataset[sample_idx]\n    figure.add_subplot(rows, cols, i)\n    plt.title(sample_lbl)\n    plt.axis(\"off\")\n    plt.imshow(sample_img.squeeze(), cmap=\"gray\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-03T13:40:17.724247Z","iopub.execute_input":"2022-07-03T13:40:17.724704Z","iopub.status.idle":"2022-07-03T13:40:18.309649Z","shell.execute_reply.started":"2022-07-03T13:40:17.724668Z","shell.execute_reply":"2022-07-03T13:40:18.308450Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"Checking if the device has GPU present , if not we do the whole training process on CPU (The downside being it can be very slow)","metadata":{}},{"cell_type":"code","source":"## Checking if the GPU is being used properly . \n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint('Using device:', device)\ntorch.cuda.is_available()\nx0 = x0.to(device)\nprint(\"x0\" , x0.is_cuda)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Creating test and valid subsets using stratified samples","metadata":{}},{"cell_type":"markdown","source":"We then proceed on splitting the training_dataset into train and valid subsets as defined above using stratified sampling . We keep the valid set as 10% of the training_dataset .Notice that when we look at the contents of train_dataloaders , the dimension is (torch.Size([64, 1, 28, 28]), torch.Size([64])) which is differnt from the contents of train_dataset torch.Size([1, 28, 28]), int). This is essentially a batch that gets processed at the time of training .","metadata":{}},{"cell_type":"code","source":"from torch.utils.data import SubsetRandomSampler\nfrom sklearn.model_selection import train_test_split\nindices = list(range(len(train_df)))\ntrain_indices , valid_indices = train_test_split(indices, test_size=0.1, stratify=train_df['label'])\n\n# Creating PT data samplers and loaders:\ntrain_sampler = SubsetRandomSampler(train_indices)\nvalid_sampler = SubsetRandomSampler(test_indices)\n\ntrain_dataloader = torch.utils.data.DataLoader(train_dataset , batch_size=64, sampler=train_sampler, num_workers=16)\nvalid_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=64, sampler=valid_sampler, num_workers=16)\n\nx0 , y0 = next(iter(train_dataloader))\nx0.shape , y0.shape","metadata":{"execution":{"iopub.status.busy":"2022-07-03T13:41:00.462217Z","iopub.execute_input":"2022-07-03T13:41:00.463102Z","iopub.status.idle":"2022-07-03T13:41:02.354506Z","shell.execute_reply.started":"2022-07-03T13:41:00.463047Z","shell.execute_reply":"2022-07-03T13:41:02.353163Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"## Defining NN Model ","metadata":{}},{"cell_type":"markdown","source":"Now that we are finished with defining the dataloaders , we then proceed to defining the details of the Neural Netowrk are going to be using for predictions. We use an architecture with 2 hidden layers and with the output layer having 10 Nodes (since there are 10 differnt classes for prediciton) . We define our our class inheriting the nn.Module to define our own forward propagation function since it's considered as best practice while working on pytorch .\n\nThe model would look as follows :\n\n* We flatten our 28*28 image into a tensor of length 784 (which is achieved through nn.Flatten)\n* We then input these into a hidden layer containing 128 nodes which is then connected to another hidden layer with 64 nodes. We use Relu as activation function inbetween layers \n* Finally we then connect the hidden layer with a layer having 10 nodes (Equivalent to the number of labels) \n\n<p> Notice that there's no softmax layer at the end of the NN . This is because the <b> nn.CrossEntropyLoss() </b> automatically applies softmax from the output obtained to calculate loss . However , if we use <b> nn.NLLLLoss() </b> as our loss fucntion , then we would have to include <b> nn.LogSoftmax </b> at the end of nn.Sequential(..) </p>","metadata":{}},{"cell_type":"code","source":"from torch import nn\n\n# Get cpu or gpu device for training.\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(f\"Using {device} device\")\n\nclass MyOwnNeuralNetwork(nn.Module):\n    def __init__(self):\n        super(MyOwnNeuralNetwork, self).__init__()\n        self.flatten = nn.Flatten()\n        self.linear_relu_stack = nn.Sequential(\n            nn.Linear(784, 128),\n            nn.ReLU(),\n            nn.Linear(128, 64),\n            nn.ReLU(),\n            nn.Linear(64, 10)\n            ## Softmax layer ignored since the loss function defined is nn.CrossEntropy()\n        )\n\n    def forward(self, x):\n        x = self.flatten(x)\n        logits = self.linear_relu_stack(x)\n        return  logits\n    \n    \nmodel = MyOwnNeuralNetwork().to(device)\nprint(model)\n\n# model = model.cuda()\n# torch.backends.cudnn.benchmark=True\n# torch.cuda.set_device(0)","metadata":{"execution":{"iopub.status.busy":"2022-07-03T13:54:40.988027Z","iopub.execute_input":"2022-07-03T13:54:40.989439Z","iopub.status.idle":"2022-07-03T13:54:41.007586Z","shell.execute_reply.started":"2022-07-03T13:54:40.989345Z","shell.execute_reply":"2022-07-03T13:54:41.004511Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"## Defining Optimizers and loss function","metadata":{}},{"cell_type":"markdown","source":"We will use cross entrpy loss as loss function and stocastic gradient descent as optimizer for this particular exercise","metadata":{}},{"cell_type":"code","source":"## Defining optimizer and loss functions \n\nloss_fn = nn.CrossEntropyLoss()\noptimizer = torch.optim.SGD(model.parameters(), lr=3e-3, momentum=0.9)","metadata":{"execution":{"iopub.status.busy":"2022-07-03T13:55:38.465143Z","iopub.execute_input":"2022-07-03T13:55:38.466682Z","iopub.status.idle":"2022-07-03T13:55:38.474287Z","shell.execute_reply.started":"2022-07-03T13:55:38.466601Z","shell.execute_reply":"2022-07-03T13:55:38.472951Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"## Defining Train loop","metadata":{}},{"cell_type":"code","source":"from torch.autograd import Variable\ndef train(dataloader, model, loss_fn, optimizer):\n    \n    # Total size of dataset for reference\n    size = len(dataloader.dataset)\n    \n    # places your model into training mode\n    model.train()\n    \n    correct = 0\n    # Gives X , y for each batch\n    for batch, (X, y) in enumerate(dataloader):\n        \n        # Converting device to cuda\n        X, y = X.to(device), y.to(device)\n        model.to(device)\n        \n        # Compute prediction error / loss\n        # 1. Compute y_pred \n        # 2. Compute loss between y and y_pred using selectd loss function\n        \n        y_pred = model(X)\n        loss = loss_fn(y_pred, y)\n\n        # Backpropagation on optimizing for loss\n        # 1. Sets gradients as 0 \n        # 2. Compute the gradients using back_prop\n        # 3. update the parameters using the gradients from step 2\n        \n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        correct += (y_pred.argmax(1) == y).type(torch.float).sum().item()\n        \n        if batch % 100 == 0:\n            loss, current = loss.item(), batch * len(X)\n            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n    correct/=size\n    print(f\"Train Accuracy: {(100*correct):>0.1f}%\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Defining valid/test loop","metadata":{}},{"cell_type":"code","source":"def validation(dataloader, model, loss_fn):\n    \n    # Total size of dataset for reference\n    size = 0\n    num_batches = len(dataloader)\n    \n    # Explanation given above\n    model.eval()\n\n    test_loss, correct = 0, 0\n    with torch.no_grad():\n        \n        # Gives X , y for each batch\n        for X, y in dataloader:\n            X, y = X.to(device), y.to(device)\n            model.to(device)\n            pred = model(X)\n            test_loss += loss_fn(pred, y).item()\n            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n            size+=len(y)\n    \n    ## Calculating loss based on loss function defined\n    test_loss /= num_batches\n    \n    ## Calculating Accuracy based on how many y match with y_pred\n    print(size)\n    correct /= size\n    \n    print(f\"Valid Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training and validation triggers ","metadata":{}},{"cell_type":"code","source":"epochs = 10\nfor t in range(epochs):\n    print(f\"Epoch {t+1}\\n-------------------------------\")\n    train(train_dataloader, model, loss_fn, optimizer)\n    validation(valid_dataloader, model, loss_fn)\nprint(\"Done!\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}